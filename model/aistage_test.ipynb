{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchvision\n",
    "from torchvision import transforms, utils\n",
    "from torchvision.transforms import Resize, ToTensor, Normalize\n",
    "from torch.utils.data import Dataset, DataLoader, random_split, SubsetRandomSampler, WeightedRandomSampler\n",
    "\n",
    "from PIL import Image\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_PATH = '/opt/ml/input/data/train/'\n",
    "TRAIN_IMAGE_PATH = '/opt/ml/input/data/train/processed_train_images/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>gender</th>\n",
       "      <th>path</th>\n",
       "      <th>mask</th>\n",
       "      <th>age</th>\n",
       "      <th>age_3</th>\n",
       "      <th>age_11</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>003792</td>\n",
       "      <td>0</td>\n",
       "      <td>/opt/ml/input/data/train/processed_train_image...</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>000036</td>\n",
       "      <td>1</td>\n",
       "      <td>/opt/ml/input/data/train/processed_train_image...</td>\n",
       "      <td>0</td>\n",
       "      <td>58</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>003880</td>\n",
       "      <td>1</td>\n",
       "      <td>/opt/ml/input/data/train/processed_train_image...</td>\n",
       "      <td>0</td>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>003136</td>\n",
       "      <td>1</td>\n",
       "      <td>/opt/ml/input/data/train/processed_train_image...</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>006167</td>\n",
       "      <td>1</td>\n",
       "      <td>/opt/ml/input/data/train/processed_train_image...</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18888</th>\n",
       "      <td>18888</td>\n",
       "      <td>003361</td>\n",
       "      <td>1</td>\n",
       "      <td>/opt/ml/input/data/train/processed_train_image...</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18889</th>\n",
       "      <td>18889</td>\n",
       "      <td>006170</td>\n",
       "      <td>1</td>\n",
       "      <td>/opt/ml/input/data/train/processed_train_image...</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18890</th>\n",
       "      <td>18890</td>\n",
       "      <td>003172</td>\n",
       "      <td>1</td>\n",
       "      <td>/opt/ml/input/data/train/processed_train_image...</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18891</th>\n",
       "      <td>18891</td>\n",
       "      <td>001531</td>\n",
       "      <td>1</td>\n",
       "      <td>/opt/ml/input/data/train/processed_train_image...</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18892</th>\n",
       "      <td>18892</td>\n",
       "      <td>006556</td>\n",
       "      <td>0</td>\n",
       "      <td>/opt/ml/input/data/train/processed_train_image...</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18893 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0      id  gender  \\\n",
       "0               0  003792       0   \n",
       "1               1  000036       1   \n",
       "2               2  003880       1   \n",
       "3               3  003136       1   \n",
       "4               4  006167       1   \n",
       "...           ...     ...     ...   \n",
       "18888       18888  003361       1   \n",
       "18889       18889  006170       1   \n",
       "18890       18890  003172       1   \n",
       "18891       18891  001531       1   \n",
       "18892       18892  006556       0   \n",
       "\n",
       "                                                    path  mask  age  age_3  \\\n",
       "0      /opt/ml/input/data/train/processed_train_image...     0   30      1   \n",
       "1      /opt/ml/input/data/train/processed_train_image...     0   58      1   \n",
       "2      /opt/ml/input/data/train/processed_train_image...     0   55      1   \n",
       "3      /opt/ml/input/data/train/processed_train_image...     0   19      0   \n",
       "4      /opt/ml/input/data/train/processed_train_image...     0   18      0   \n",
       "...                                                  ...   ...  ...    ...   \n",
       "18888  /opt/ml/input/data/train/processed_train_image...     0   20      0   \n",
       "18889  /opt/ml/input/data/train/processed_train_image...     0   20      0   \n",
       "18890  /opt/ml/input/data/train/processed_train_image...     0   19      0   \n",
       "18891  /opt/ml/input/data/train/processed_train_image...     0   26      0   \n",
       "18892  /opt/ml/input/data/train/processed_train_image...     0   21      0   \n",
       "\n",
       "       age_11  label  \n",
       "0           3      1  \n",
       "1           5      4  \n",
       "2           5      4  \n",
       "3           1      3  \n",
       "4           1      3  \n",
       "...       ...    ...  \n",
       "18888       2      3  \n",
       "18889       2      3  \n",
       "18890       1      3  \n",
       "18891       2      3  \n",
       "18892       2      0  \n",
       "\n",
       "[18893 rows x 9 columns]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv(os.path.join(TRAIN_PATH, 'preprocessed_train.csv'))\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "class maskDataset(Dataset):\n",
    "    def __init__(self, train_df, transform, train=True):\n",
    "        self.train = train\n",
    "        self.transform = transform\n",
    "\n",
    "        if self.train == True:\n",
    "            self.paths = train_df['path']\n",
    "            self.labels = train_df['label']\n",
    "        else:\n",
    "            self.paths = train_df\n",
    "        \n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        if self.train:\n",
    "            image = Image.open(self.paths.iloc[index])\n",
    "            label = self.labels.iloc[index]\n",
    "        else:\n",
    "            image = Image.open(self.paths[index])\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        if self.train:\n",
    "            return image, torch.tensor(label)\n",
    "        else:\n",
    "            return image\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    Resize((512, 384), Image.BILINEAR),\n",
    "    ToTensor(),\n",
    "    Normalize(mean=(0.5, 0.5, 0.5), std=(0.2, 0.2, 0.2))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train, valid = train_test_split(train_df, test_size=0.2, shuffle=True, stratify=train_df['label'], random_state=34)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((15114, 9), (3779, 9))"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape, valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = maskDataset(train, transform)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, drop_last=True, num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_dataset = maskDataset(valid, transform)\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size=BATCH_SIZE, shuffle=True, drop_last=True, num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 3, 512, 384])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(train_dataloader))[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "ResNet18 = torchvision.models.resnet18(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My Device : cuda:0\n"
     ]
    }
   ],
   "source": [
    "ResNet18.fc = torch.nn.Linear(in_features=512, out_features=18, bias=True)\n",
    "\n",
    "torch.nn.init.kaiming_normal_(ResNet18.fc.weight)\n",
    "torch.nn.init.zeros_(ResNet18.fc.bias)\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print ('My Device :', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "ResNet18.to(device)\n",
    "\n",
    "LEARNING_RATE = 1e-5\n",
    "NUM_EPOCH = 5\n",
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(ResNet18.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "dataloaders = {\n",
    "    \"train\" : train_dataloader,\n",
    "    \"valid\" : valid_dataloader\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b826012488943aa905a9eb12075d98d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[train] 현재 EPOCH : 0, loss : 1.2157697855550744, acc : 0.6334524154663086\n",
      "[valid] 현재 EPOCH : 0, loss : 0.49548462693354983, acc : 0.8504894971847534\n",
      "[train] 현재 EPOCH : 1, loss : 0.3766939656135344, acc : 0.8957257866859436\n",
      "[valid] 현재 EPOCH : 1, loss : 0.2851104377974717, acc : 0.898121178150177\n",
      "[train] 현재 EPOCH : 2, loss : 0.2341741240338483, acc : 0.9320496916770935\n",
      "[valid] 현재 EPOCH : 2, loss : 0.20980334603682368, acc : 0.9198200106620789\n",
      "[train] 현재 EPOCH : 3, loss : 0.16553642037717126, acc : 0.9535529613494873\n",
      "[valid] 현재 EPOCH : 3, loss : 0.1704786141166677, acc : 0.9301401972770691\n",
      "[train] 현재 EPOCH : 4, loss : 0.12013588908237015, acc : 0.9692999720573425\n",
      "[valid] 현재 EPOCH : 4, loss : 0.13433082951033168, acc : 0.9417834877967834\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_acc = 0\n",
    "best_loss = 0\n",
    "\n",
    "for epoch in tqdm(range(NUM_EPOCH)):\n",
    "    for phase in ['train', 'valid']:\n",
    "        running_loss = 0\n",
    "        running_acc = 0\n",
    "\n",
    "        if phase == 'train':\n",
    "            ResNet18.train()\n",
    "        elif phase == 'valid':\n",
    "            ResNet18.eval()\n",
    "\n",
    "        for idx, (images, labels) in enumerate(dataloaders[phase]):\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            with torch.set_grad_enabled(phase == 'train'):\n",
    "                logits = ResNet18(images)\n",
    "                _, pred = torch.max(logits, 1)\n",
    "                loss = loss_fn(logits, labels)\n",
    "\n",
    "                if phase == 'train':\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "            running_loss += loss.item() * images.size(0)\n",
    "            running_acc += torch.sum(pred == labels.data)\n",
    "            \n",
    "\n",
    "        epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
    "        epoch_acc = running_acc / len(dataloaders[phase].dataset)\n",
    "\n",
    "\n",
    "        print (f'[{phase}] 현재 EPOCH : {epoch}, loss : {epoch_loss}, acc : {epoch_acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_DIR = '/opt/ml/input/data/eval/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "300a2e5fde444d0faff959174f736be2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=12600.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "test inference is done!\n"
     ]
    }
   ],
   "source": [
    "# meta 데이터와 이미지 경로를 불러옵니다\n",
    "submission = pd.read_csv(os.path.join(TEST_DIR, 'info.csv'))\n",
    "image_dir = os.path.join(TEST_DIR, 'images')\n",
    "\n",
    "# Test Dataset 클래스 객체를 생성하고 DataLoader를 만듭니다.\n",
    "image_paths = [os.path.join(image_dir, img_id) for img_id in submission.ImageID]\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    Resize((512, 384), Image.BILINEAR),\n",
    "    ToTensor(),\n",
    "    Normalize(mean=(0.5, 0.5, 0.5), std=(0.2, 0.2, 0.2)),\n",
    "])\n",
    "dataset = maskDataset(image_paths, transform, train=False)\n",
    "loader = DataLoader(\n",
    "    dataset,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# 모델을 정의합니다. (학습한 모델이 있다면 torch.load로 모델을 불러주세요!)\n",
    "device = torch.device('cuda')\n",
    "ResNet18.eval()\n",
    "\n",
    "# 모델이 테스트 데이터셋을 예측하고 결과를 저장합니다.\n",
    "all_predictions = []\n",
    "for images in tqdm(loader):\n",
    "    images = images.to(device)\n",
    "    with torch.no_grad():\n",
    "        logits = ResNet18(images)\n",
    "        _, pred = torch.max(logits, 1)\n",
    "        # pred = pred.argmax(dim=-1)\n",
    "        all_predictions.extend(pred.cpu().numpy())\n",
    "submission['ans'] = all_predictions\n",
    "\n",
    "# 제출할 파일을 저장합니다.\n",
    "submission.to_csv(os.path.join(TEST_DIR, 'submission.csv'), index=False)\n",
    "print('test inference is done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4, 5]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(submission['ans'].unique())"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
