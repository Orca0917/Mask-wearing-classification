{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pip install efficientnet_pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchvision\n",
    "from torchvision import transforms, utils\n",
    "from torchvision.transforms import Resize, ToTensor, Normalize, RandomVerticalFlip\n",
    "from torch.utils.data import Dataset, DataLoader, random_split, SubsetRandomSampler, WeightedRandomSampler\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "\n",
    "from PIL import Image\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from efficientnet_pytorch import EfficientNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_PATH = '/opt/ml/input/data/train/'\n",
    "TRAIN_IMAGE_PATH = '/opt/ml/input/data/train/processed_train_images/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>gender</th>\n",
       "      <th>mask</th>\n",
       "      <th>age</th>\n",
       "      <th>age_3</th>\n",
       "      <th>age_11</th>\n",
       "      <th>label</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9640</th>\n",
       "      <td>9640</td>\n",
       "      <td>004371</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>/opt/ml/input/data/train/processed_train_image...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13259</th>\n",
       "      <td>13259</td>\n",
       "      <td>006231</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>/opt/ml/input/data/train/processed_train_image...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6014</th>\n",
       "      <td>6014</td>\n",
       "      <td>006728</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>/opt/ml/input/data/train/processed_train_image...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12101</th>\n",
       "      <td>12101</td>\n",
       "      <td>006652</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>/opt/ml/input/data/train/processed_train_image...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10144</th>\n",
       "      <td>10144</td>\n",
       "      <td>003617</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>/opt/ml/input/data/train/processed_train_image...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2620</th>\n",
       "      <td>2620</td>\n",
       "      <td>001573</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>/opt/ml/input/data/train/processed_train_image...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9269</th>\n",
       "      <td>9269</td>\n",
       "      <td>001407</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>/opt/ml/input/data/train/processed_train_image...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12071</th>\n",
       "      <td>12071</td>\n",
       "      <td>004246</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>/opt/ml/input/data/train/processed_train_image...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17012</th>\n",
       "      <td>17012</td>\n",
       "      <td>003669</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>59</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>/opt/ml/input/data/train/processed_train_image...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16308</th>\n",
       "      <td>16308</td>\n",
       "      <td>003725</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>58</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>/opt/ml/input/data/train/processed_train_image...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0      id  gender  mask  age  age_3  age_11  label  \\\n",
       "9640         9640  004371       1     0   56      1       5      4   \n",
       "13259       13259  006231       0     0   20      0       2      0   \n",
       "6014         6014  006728       0     0   19      0       1      0   \n",
       "12101       12101  006652       0     0   20      0       2      0   \n",
       "10144       10144  003617       0     0   56      1       5      1   \n",
       "2620         2620  001573       1     2   34      1       3     16   \n",
       "9269         9269  001407       0     0   43      1       4      1   \n",
       "12071       12071  004246       1     1   38      1       3     10   \n",
       "17012       17012  003669       0     0   59      1       5      1   \n",
       "16308       16308  003725       0     2   58      1       5     13   \n",
       "\n",
       "                                                    path  \n",
       "9640   /opt/ml/input/data/train/processed_train_image...  \n",
       "13259  /opt/ml/input/data/train/processed_train_image...  \n",
       "6014   /opt/ml/input/data/train/processed_train_image...  \n",
       "12101  /opt/ml/input/data/train/processed_train_image...  \n",
       "10144  /opt/ml/input/data/train/processed_train_image...  \n",
       "2620   /opt/ml/input/data/train/processed_train_image...  \n",
       "9269   /opt/ml/input/data/train/processed_train_image...  \n",
       "12071  /opt/ml/input/data/train/processed_train_image...  \n",
       "17012  /opt/ml/input/data/train/processed_train_image...  \n",
       "16308  /opt/ml/input/data/train/processed_train_image...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv(os.path.join(TRAIN_PATH, 'preprocessed_train.csv'))\n",
    "train_df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class maskDataset(Dataset):\n",
    "    def __init__(self, train_df, transform, train=True):\n",
    "        self.train = train\n",
    "        self.transform = transform\n",
    "\n",
    "        if self.train == True:\n",
    "            self.paths = train_df['path']\n",
    "            self.labels = train_df['age_3']\n",
    "        else:\n",
    "            self.paths = train_df\n",
    "        \n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        if self.train:\n",
    "            image = Image.open(self.paths.iloc[index])\n",
    "            label = self.labels.iloc[index]\n",
    "        else:\n",
    "            image = Image.open(self.paths[index])\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        if self.train:\n",
    "            return image, torch.tensor(label)\n",
    "        else:\n",
    "            return image\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    # Resize((512, 384), Image.BILINEAR),\n",
    "    ToTensor(),\n",
    "    # Normalize(mean=(0.5, 0.5, 0.5), std=(0.2, 0.2, 0.2))\n",
    "    RandomVerticalFlip()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train, valid = train_test_split(train_df, test_size=0.2, shuffle=True, stratify=train_df['label'], random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((15114, 9), (3779, 9))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape, valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = maskDataset(train, transform)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, drop_last=True, num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_dataset = maskDataset(valid, transform)\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size=BATCH_SIZE, shuffle=True, drop_last=True, num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 3, 512, 384])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(train_dataloader))[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/lukemelas/EfficientNet-PyTorch/releases/download/1.0/efficientnet-b0-355c32eb.pth\" to /opt/ml/.cache/torch/hub/checkpoints/efficientnet-b0-355c32eb.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9606706c687f4cca8230e75009623e0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=21388428.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loaded pretrained weights for efficientnet-b0\n",
      "My Device : cuda:0\n"
     ]
    }
   ],
   "source": [
    "class EfficientNet_MultiLabel(nn.Module):\n",
    "    def __init__(self, in_channels=3, num_classes=3):\n",
    "        super(EfficientNet_MultiLabel, self).__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.num_classes = num_classes\n",
    "        self.network = EfficientNet.from_pretrained('efficientnet-b0', in_channels=self.in_channels, num_classes=self.num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.network(x)\n",
    "\n",
    "efficientNet = EfficientNet_MultiLabel()\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print ('My Device :', device)\n",
    "efficientNet = efficientNet.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATE = 1e-4\n",
    "NUM_EPOCH = 10\n",
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(efficientNet.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "dataloaders = {\n",
    "    \"train\" : train_dataloader,\n",
    "    \"valid\" : valid_dataloader\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler = CosineAnnealingLR(optimizer=optimizer, T_max=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "093091b0c344411ea42c7781e7e72f03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=10.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[train] 현재 EPOCH : 0, loss : 0.282469979832061, acc : 0.8987031579017639\n",
      "[valid] 현재 EPOCH : 0, loss : 0.14091086961756816, acc : 0.9396665692329407\n",
      "[train] 현재 EPOCH : 1, loss : 0.10675641427607042, acc : 0.9602354764938354\n",
      "[valid] 현재 EPOCH : 1, loss : 0.0587857291753029, acc : 0.9780364632606506\n",
      "[train] 현재 EPOCH : 2, loss : 0.04933021511856417, acc : 0.9836574792861938\n",
      "[valid] 현재 EPOCH : 2, loss : 0.08215932732782656, acc : 0.9714210033416748\n",
      "[train] 현재 EPOCH : 3, loss : 0.03127837554236537, acc : 0.989281415939331\n",
      "[valid] 현재 EPOCH : 3, loss : 0.024553267296317884, acc : 0.9902090430259705\n",
      "[train] 현재 EPOCH : 4, loss : 0.0185572738305451, acc : 0.9938467144966125\n",
      "[valid] 현재 EPOCH : 4, loss : 0.02856280219283514, acc : 0.9867689609527588\n",
      "[train] 현재 EPOCH : 5, loss : 0.01318413883894884, acc : 0.9953023195266724\n",
      "[valid] 현재 EPOCH : 5, loss : 0.019652650114359568, acc : 0.9923259615898132\n",
      "[train] 현재 EPOCH : 6, loss : 0.009475189416543729, acc : 0.9966256022453308\n",
      "[valid] 현재 EPOCH : 6, loss : 0.009047311490705248, acc : 0.9960306882858276\n",
      "[train] 현재 EPOCH : 7, loss : 0.00766798870694888, acc : 0.9969564080238342\n",
      "[valid] 현재 EPOCH : 7, loss : 0.009327750690488407, acc : 0.9960306882858276\n",
      "[train] 현재 EPOCH : 8, loss : 0.006518182201514708, acc : 0.9979488849639893\n",
      "[valid] 현재 EPOCH : 8, loss : 0.008653356959570379, acc : 0.9965599179267883\n",
      "[train] 현재 EPOCH : 9, loss : 0.005679180536348167, acc : 0.9977504014968872\n",
      "[valid] 현재 EPOCH : 9, loss : 0.008092528494783723, acc : 0.9965599179267883\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_acc = 0\n",
    "best_loss = 0\n",
    "\n",
    "PRINT_EVERY = 10\n",
    "\n",
    "for epoch in tqdm(range(NUM_EPOCH)):\n",
    "    for phase in ['train', 'valid']:\n",
    "        running_loss = 0\n",
    "        running_acc = 0\n",
    "\n",
    "        if phase == 'train':\n",
    "            efficientNet.train()\n",
    "        elif phase == 'valid':\n",
    "            efficientNet.eval()\n",
    "\n",
    "        for idx, (images, labels) in enumerate(dataloaders[phase]):\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            with torch.set_grad_enabled(phase == 'train'):\n",
    "                logits = efficientNet(images)\n",
    "                _, pred = torch.max(logits, 1)\n",
    "                loss = loss_fn(logits, labels)\n",
    "\n",
    "                if phase == 'train':\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "            running_loss += loss.item() * images.size(0)\n",
    "            running_acc += torch.sum(pred == labels.data)\n",
    "\n",
    "            # if idx % PRINT_EVERY == 0:\n",
    "            #     train_loss = running_loss / PRINT_EVERY\n",
    "            #     train_acc = running_acc / BATCH_SIZE / PRINT_EVERY\n",
    "            #     print (f\"Epoch={epoch}, Training Loss={train_loss:4.4}, Training Accuracy={train_acc:4.2%}, lr={LEARNING_RATE}\")\n",
    "            \n",
    "        scheduler.step()\n",
    "\n",
    "        epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
    "        epoch_acc = running_acc / len(dataloaders[phase].dataset)\n",
    "        print (f'[{phase}] 현재 EPOCH : {epoch}, loss : {epoch_loss}, acc : {epoch_acc}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_DIR = '/opt/ml/input/data/eval/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# meta 데이터와 이미지 경로를 불러옵니다\n",
    "submission = pd.read_csv(os.path.join(TEST_DIR, 'info.csv'))\n",
    "image_dir = os.path.join(TEST_DIR, 'images')\n",
    "\n",
    "# Test Dataset 클래스 객체를 생성하고 DataLoader를 만듭니다.\n",
    "image_paths = [os.path.join(image_dir, img_id) for img_id in submission.ImageID]\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    Resize((512, 384), Image.BILINEAR),\n",
    "    ToTensor(),\n",
    "    Normalize(mean=(0.5, 0.5, 0.5), std=(0.2, 0.2, 0.2)),\n",
    "])\n",
    "dataset = maskDataset(image_paths, transform, train=False)\n",
    "loader = DataLoader(\n",
    "    dataset,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# 모델을 정의합니다. (학습한 모델이 있다면 torch.load로 모델을 불러주세요!)\n",
    "device = torch.device('cuda')\n",
    "ResNet18.eval()\n",
    "\n",
    "# 모델이 테스트 데이터셋을 예측하고 결과를 저장합니다.\n",
    "all_predictions = []\n",
    "for images in tqdm(loader):\n",
    "    images = images.to(device)\n",
    "    with torch.no_grad():\n",
    "        logits = ResNet18(images)\n",
    "        _, pred = torch.max(logits, 1)\n",
    "        # pred = pred.argmax(dim=-1)\n",
    "        all_predictions.extend(pred.cpu().numpy())\n",
    "submission['ans'] = all_predictions\n",
    "\n",
    "# 제출할 파일을 저장합니다.\n",
    "submission.to_csv(os.path.join(TEST_DIR, 'submission.csv'), index=False)\n",
    "print('test inference is done!')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
